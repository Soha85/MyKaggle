{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "939f11a0",
   "metadata": {
    "papermill": {
     "duration": 0.012302,
     "end_time": "2024-02-05T17:32:38.907149",
     "exception": false,
     "start_time": "2024-02-05T17:32:38.894847",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Count-Based methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05351768",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:38.930896Z",
     "iopub.status.busy": "2024-02-05T17:32:38.930277Z",
     "iopub.status.idle": "2024-02-05T17:32:38.945518Z",
     "shell.execute_reply": "2024-02-05T17:32:38.943827Z"
    },
    "papermill": {
     "duration": 0.031808,
     "end_time": "2024-02-05T17:32:38.948758",
     "exception": false,
     "start_time": "2024-02-05T17:32:38.916950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Doc_1= \"The cat in the hat\"\n",
    "Doc_2= \"The quick brown fox\"\n",
    "Doc_3= \"The hat is blue\"\n",
    "\n",
    "Docs =[Doc_1,Doc_2,Doc_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233a7058",
   "metadata": {
    "papermill": {
     "duration": 0.010545,
     "end_time": "2024-02-05T17:32:38.968992",
     "exception": false,
     "start_time": "2024-02-05T17:32:38.958447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Term Frequency (TF)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b575962",
   "metadata": {
    "papermill": {
     "duration": 0.008499,
     "end_time": "2024-02-05T17:32:38.986803",
     "exception": false,
     "start_time": "2024-02-05T17:32:38.978304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **TF(t,d) is the term frequency of term t in document d (how often the term appears in the document).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51cebd9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:39.008546Z",
     "iopub.status.busy": "2024-02-05T17:32:39.008042Z",
     "iopub.status.idle": "2024-02-05T17:32:39.017354Z",
     "shell.execute_reply": "2024-02-05T17:32:39.016344Z"
    },
    "papermill": {
     "duration": 0.024498,
     "end_time": "2024-02-05T17:32:39.020643",
     "exception": false,
     "start_time": "2024-02-05T17:32:38.996145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blue', 'brown', 'cat', 'fox', 'hat', 'in', 'is', 'quick', 'the'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "for d in Docs:\n",
    "    lst.extend(d.lower().split(' '))\n",
    "wrds = set(lst) # remove duplicate words\n",
    "wrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcef32b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:39.041346Z",
     "iopub.status.busy": "2024-02-05T17:32:39.040887Z",
     "iopub.status.idle": "2024-02-05T17:32:40.146548Z",
     "shell.execute_reply": "2024-02-05T17:32:40.144655Z"
    },
    "papermill": {
     "duration": 1.119094,
     "end_time": "2024-02-05T17:32:40.149364",
     "exception": false,
     "start_time": "2024-02-05T17:32:39.030270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fox</th>\n",
       "      <th>the</th>\n",
       "      <th>brown</th>\n",
       "      <th>blue</th>\n",
       "      <th>hat</th>\n",
       "      <th>in</th>\n",
       "      <th>quick</th>\n",
       "      <th>is</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    fox   the  brown  blue   hat   in  quick    is  cat\n",
       "0  0.00  0.40   0.00  0.00  0.20  0.2   0.00  0.00  0.2\n",
       "1  0.25  0.25   0.25  0.00  0.00  0.0   0.25  0.00  0.0\n",
       "2  0.00  0.25   0.00  0.25  0.25  0.0   0.00  0.25  0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#form a dataframe to represent TF for each word in each Document where columns are words and rows are documents\n",
    "import pandas as pd\n",
    "def count_wrd_Doc(wrd,doc):\n",
    "    i=0\n",
    "    for w in doc.lower().split(' '):\n",
    "        if wrd == w:\n",
    "            i = i+1\n",
    "    return i/len(doc.lower().split(' '))\n",
    "    \n",
    "tf_df = pd.DataFrame(columns=list(wrds)) #empty dataframe initialized with words column headers\n",
    "freq_lst=[] #empty list for each column to save word frequencies in each document\n",
    "for c in tf_df.columns:\n",
    "    freq_lst=[]#empty the list\n",
    "    for d in Docs:\n",
    "        freq_lst.append(count_wrd_Doc(c,d))#append the frequency of word in document d\n",
    "    tf_df[c]=freq_lst #assign values to column\n",
    "tf_df #display the dataframe of TF for each word in each document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7850904",
   "metadata": {
    "papermill": {
     "duration": 0.010143,
     "end_time": "2024-02-05T17:32:40.169545",
     "exception": false,
     "start_time": "2024-02-05T17:32:40.159402",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Document Frequency (DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca45c8ec",
   "metadata": {
    "papermill": {
     "duration": 0.009272,
     "end_time": "2024-02-05T17:32:40.188243",
     "exception": false,
     "start_time": "2024-02-05T17:32:40.178971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **Calculate Document Frequency (DF): the word appears in how many documents**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "846db270",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:40.210688Z",
     "iopub.status.busy": "2024-02-05T17:32:40.209925Z",
     "iopub.status.idle": "2024-02-05T17:32:40.232323Z",
     "shell.execute_reply": "2024-02-05T17:32:40.230785Z"
    },
    "papermill": {
     "duration": 0.037938,
     "end_time": "2024-02-05T17:32:40.236214",
     "exception": false,
     "start_time": "2024-02-05T17:32:40.198276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fox</th>\n",
       "      <th>the</th>\n",
       "      <th>brown</th>\n",
       "      <th>blue</th>\n",
       "      <th>hat</th>\n",
       "      <th>in</th>\n",
       "      <th>quick</th>\n",
       "      <th>is</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fox  the  brown  blue  hat  in  quick  is  cat\n",
       "0    1    3      1     1    2   1      1   1    1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_df = pd.DataFrame(columns=list(wrds)) #empty dataframe initialized with words column headers\n",
    "for c in df_df.columns:\n",
    "    df_df[c] = [sum(1 for doc in Docs if c in doc.lower().split(' '))]\n",
    "df_df #display the dataframe of DF for each word "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b7f61a",
   "metadata": {
    "papermill": {
     "duration": 0.010872,
     "end_time": "2024-02-05T17:32:40.258798",
     "exception": false,
     "start_time": "2024-02-05T17:32:40.247926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inverse Document Frequency (IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b3b478",
   "metadata": {
    "papermill": {
     "duration": 0.011092,
     "end_time": "2024-02-05T17:32:40.282578",
     "exception": false,
     "start_time": "2024-02-05T17:32:40.271486",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **IDF(t,D) is the inverse document frequency of term t in the entire document set D (logarithmically scaled inverse fraction of the documents that contain the term).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ecefa8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:40.311741Z",
     "iopub.status.busy": "2024-02-05T17:32:40.310489Z",
     "iopub.status.idle": "2024-02-05T17:32:40.335725Z",
     "shell.execute_reply": "2024-02-05T17:32:40.334324Z"
    },
    "papermill": {
     "duration": 0.041817,
     "end_time": "2024-02-05T17:32:40.338597",
     "exception": false,
     "start_time": "2024-02-05T17:32:40.296780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fox</th>\n",
       "      <th>the</th>\n",
       "      <th>brown</th>\n",
       "      <th>blue</th>\n",
       "      <th>hat</th>\n",
       "      <th>in</th>\n",
       "      <th>quick</th>\n",
       "      <th>is</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.693147</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>1.287682</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>1.693147</td>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fox  the     brown      blue       hat        in     quick        is  \\\n",
       "0  1.693147  1.0  1.693147  1.693147  1.287682  1.693147  1.693147  1.693147   \n",
       "\n",
       "        cat  \n",
       "0  1.693147  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "idf_df = pd.DataFrame(columns=list(wrds)) #empty dataframe initialized with words column headers\n",
    "for c in idf_df.columns:\n",
    "    N = 3 #No of documents\n",
    "    df = df_df[c].iloc[0] # DF of word\n",
    "    idf_df[c] = [math.log((N+1) / (df+1))+1]#IDF = log (no. of documents/DF(word)) \n",
    "idf_df #display the dataframe of idf for each word "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d171edc0",
   "metadata": {
    "papermill": {
     "duration": 0.009117,
     "end_time": "2024-02-05T17:32:40.357393",
     "exception": false,
     "start_time": "2024-02-05T17:32:40.348276",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Term Frequency - Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d258aa84",
   "metadata": {
    "papermill": {
     "duration": 0.010853,
     "end_time": "2024-02-05T17:32:40.377906",
     "exception": false,
     "start_time": "2024-02-05T17:32:40.367053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*** TF-IDF = TF * IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7051fc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:40.407696Z",
     "iopub.status.busy": "2024-02-05T17:32:40.407187Z",
     "iopub.status.idle": "2024-02-05T17:32:40.441285Z",
     "shell.execute_reply": "2024-02-05T17:32:40.439456Z"
    },
    "papermill": {
     "duration": 0.05242,
     "end_time": "2024-02-05T17:32:40.444966",
     "exception": false,
     "start_time": "2024-02-05T17:32:40.392546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fox</th>\n",
       "      <th>the</th>\n",
       "      <th>brown</th>\n",
       "      <th>blue</th>\n",
       "      <th>hat</th>\n",
       "      <th>in</th>\n",
       "      <th>quick</th>\n",
       "      <th>is</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.257536</td>\n",
       "      <td>0.338629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.423287</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.423287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423287</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423287</td>\n",
       "      <td>0.321921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423287</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fox   the     brown      blue       hat        in     quick        is  \\\n",
       "0  0.000000  0.40  0.000000  0.000000  0.257536  0.338629  0.000000  0.000000   \n",
       "1  0.423287  0.25  0.423287  0.000000  0.000000  0.000000  0.423287  0.000000   \n",
       "2  0.000000  0.25  0.000000  0.423287  0.321921  0.000000  0.000000  0.423287   \n",
       "\n",
       "        cat  \n",
       "0  0.338629  \n",
       "1  0.000000  \n",
       "2  0.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df = pd.DataFrame(columns=list(wrds)) #empty dataframe initialized with words column headers\n",
    "tfidf_lst=[]  #empty list for each column \n",
    "for c in tfidf_df.columns:\n",
    "    tfidf_lst=[] #empty list for each column\n",
    "    for i in range(0,len(Docs)):\n",
    "        tf_idf_d1 = tf_df[c].iloc[i]*idf_df[c].iloc[0] #append tf of word in i th document to idf of word\n",
    "        tfidf_lst.append(tf_idf_d1)\n",
    "    tfidf_df[c]=tfidf_lst#assign tfidf values for each word\n",
    "tfidf_df #display the dataframe of tf-idf for all words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d79b32",
   "metadata": {
    "papermill": {
     "duration": 0.014638,
     "end_time": "2024-02-05T17:32:40.475560",
     "exception": false,
     "start_time": "2024-02-05T17:32:40.460922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# L2 Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d478bc7b",
   "metadata": {
    "papermill": {
     "duration": 0.013493,
     "end_time": "2024-02-05T17:32:40.503242",
     "exception": false,
     "start_time": "2024-02-05T17:32:40.489749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **L2 normalization, also known as Euclidean normalization or L2 norm normalization, is a technique used to scale vectors (or arrays) in such a way that their Euclidean norm becomes equal to 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e30ba73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:40.529610Z",
     "iopub.status.busy": "2024-02-05T17:32:40.528667Z",
     "iopub.status.idle": "2024-02-05T17:32:40.560352Z",
     "shell.execute_reply": "2024-02-05T17:32:40.558762Z"
    },
    "papermill": {
     "duration": 0.047732,
     "end_time": "2024-02-05T17:32:40.562990",
     "exception": false,
     "start_time": "2024-02-05T17:32:40.515258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fox</th>\n",
       "      <th>the</th>\n",
       "      <th>brown</th>\n",
       "      <th>blue</th>\n",
       "      <th>hat</th>\n",
       "      <th>in</th>\n",
       "      <th>quick</th>\n",
       "      <th>is</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381519</td>\n",
       "      <td>0.501651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.322745</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345205</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.444514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fox       the     brown      blue       hat        in     quick  \\\n",
       "0  0.000000  0.592567  0.000000  0.000000  0.381519  0.501651  0.000000   \n",
       "1  0.546454  0.322745  0.546454  0.000000  0.000000  0.000000  0.546454   \n",
       "2  0.000000  0.345205  0.000000  0.584483  0.444514  0.000000  0.000000   \n",
       "\n",
       "         is       cat  \n",
       "0  0.000000  0.501651  \n",
       "1  0.000000  0.000000  \n",
       "2  0.584483  0.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_df = pd.DataFrame(columns=tfidf_df.columns)\n",
    "\n",
    "# Apply L2 normalization to each document's TF-IDF values\n",
    "for i,row in enumerate(tfidf_df.iterrows()):\n",
    "    # Extract TF-IDF values    \n",
    "    tfidf_values_list = list(tfidf_df.iloc[i].values)\n",
    "    # Calculate L2 norm\n",
    "    l2_norm = math.sqrt(sum(val**2 for val in tfidf_values_list))\n",
    "    # Normalize TF-IDF values using L2 norm\n",
    "    normalized_tfidf = [val / l2_norm for val in list(tfidf_df.iloc[i].values)]\n",
    "    new_row = pd.Series(normalized_tfidf, index=tfidf_df.columns)\n",
    "    normalized_df.loc[len(normalized_df)] = new_row\n",
    "    \n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6692fe3",
   "metadata": {
    "papermill": {
     "duration": 0.00949,
     "end_time": "2024-02-05T17:32:40.582864",
     "exception": false,
     "start_time": "2024-02-05T17:32:40.573374",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TfidfVectorizer Python Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd09ac92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:40.607331Z",
     "iopub.status.busy": "2024-02-05T17:32:40.606362Z",
     "iopub.status.idle": "2024-02-05T17:32:42.072939Z",
     "shell.execute_reply": "2024-02-05T17:32:42.071690Z"
    },
    "papermill": {
     "duration": 1.481837,
     "end_time": "2024-02-05T17:32:42.075814",
     "exception": false,
     "start_time": "2024-02-05T17:32:40.593977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blue</th>\n",
       "      <th>brown</th>\n",
       "      <th>cat</th>\n",
       "      <th>fox</th>\n",
       "      <th>hat</th>\n",
       "      <th>in</th>\n",
       "      <th>is</th>\n",
       "      <th>quick</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381519</td>\n",
       "      <td>0.501651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.546454</td>\n",
       "      <td>0.322745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.444514</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       blue     brown       cat       fox       hat        in        is  \\\n",
       "0  0.000000  0.000000  0.501651  0.000000  0.381519  0.501651  0.000000   \n",
       "1  0.000000  0.546454  0.000000  0.546454  0.000000  0.000000  0.000000   \n",
       "2  0.584483  0.000000  0.000000  0.000000  0.444514  0.000000  0.584483   \n",
       "\n",
       "      quick       the  \n",
       "0  0.000000  0.592567  \n",
       "1  0.546454  0.322745  \n",
       "2  0.000000  0.345205  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(norm='l2',smooth_idf=True)\n",
    "\n",
    "# Fit the documents and transform them into a TF-IDF matrix\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(Docs)\n",
    "\n",
    "# Get the feature names (terms) from the vectorizer\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "df_tfidf = pd.DataFrame(data=tfidf_matrix.toarray(), columns=feature_names)\n",
    "df_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e705da96",
   "metadata": {
    "_kg_hide-input": true,
    "papermill": {
     "duration": 0.010058,
     "end_time": "2024-02-05T17:32:42.096825",
     "exception": false,
     "start_time": "2024-02-05T17:32:42.086767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **The TfidfVectorizer in scikit-learn, by default, adds a smoothing term to the denominator of the IDF calculation to avoid division by zero. This is done to handle the case where a term is present in all documents, ensuring that the IDF is not undefined.**\n",
    "* **L2 normalization, also known as Euclidean normalization or L2 norm normalization, is a technique used to scale vectors (or arrays) in such a way that their Euclidean norm becomes equal to 1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e9baf",
   "metadata": {
    "papermill": {
     "duration": 0.010398,
     "end_time": "2024-02-05T17:32:42.117430",
     "exception": false,
     "start_time": "2024-02-05T17:32:42.107032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Unigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7c3117",
   "metadata": {
    "papermill": {
     "duration": 0.010403,
     "end_time": "2024-02-05T17:32:42.242037",
     "exception": false,
     "start_time": "2024-02-05T17:32:42.231634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **A unigram, in the context of natural language processing (NLP) and linguistics, refers to a single unit or token of a word. It is the simplest form of linguistic analysis where text is broken down into individual words. In other words, a unigram is a term used to describe a single word in a sequence of words.**\n",
    "* **Unigrams are the building blocks for more complex linguistic analyses, such as bigrams (pairs of consecutive words), trigrams (triplets of consecutive words), and n-grams in general.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23205f97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:42.267780Z",
     "iopub.status.busy": "2024-02-05T17:32:42.266852Z",
     "iopub.status.idle": "2024-02-05T17:32:42.285571Z",
     "shell.execute_reply": "2024-02-05T17:32:42.284580Z"
    },
    "papermill": {
     "duration": 0.035447,
     "end_time": "2024-02-05T17:32:42.289141",
     "exception": false,
     "start_time": "2024-02-05T17:32:42.253694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fox</th>\n",
       "      <th>the</th>\n",
       "      <th>brown</th>\n",
       "      <th>blue</th>\n",
       "      <th>hat</th>\n",
       "      <th>in</th>\n",
       "      <th>quick</th>\n",
       "      <th>is</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fox  the  brown  blue  hat  in  quick  is  cat\n",
       "0    0    2      0     0    1   1      0   0    1\n",
       "1    1    1      1     0    0   0      1   0    0\n",
       "2    0    1      0     1    1   0      0   1    0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Probability of unigram P(w)=C(w)/m same idea of TF\n",
    "def count_wrd_Doc(wrd,doc):\n",
    "    i=0\n",
    "    for w in doc.lower().split(' '):\n",
    "        if wrd == w:\n",
    "            i = i+1\n",
    "    return i\n",
    "    \n",
    "unigram_df = pd.DataFrame(columns=list(wrds)) #empty dataframe initialized with words column headers\n",
    "freq_lst=[] #empty list for each column to save word frequencies in each document\n",
    "for c in tf_df.columns:\n",
    "    freq_lst=[]#empty the list\n",
    "    for d in Docs:\n",
    "        freq_lst.append(count_wrd_Doc(c,d))#append the frequency of word in document d\n",
    "    unigram_df[c]=freq_lst #assign values to column\n",
    "unigram_df #display the dataframe of TF for each word in each document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03aa9bfa",
   "metadata": {
    "papermill": {
     "duration": 0.015114,
     "end_time": "2024-02-05T17:32:42.320717",
     "exception": false,
     "start_time": "2024-02-05T17:32:42.305603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Unigrams python function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44774a59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:42.352720Z",
     "iopub.status.busy": "2024-02-05T17:32:42.352098Z",
     "iopub.status.idle": "2024-02-05T17:32:43.366076Z",
     "shell.execute_reply": "2024-02-05T17:32:43.364444Z"
    },
    "papermill": {
     "duration": 1.031749,
     "end_time": "2024-02-05T17:32:43.369025",
     "exception": false,
     "start_time": "2024-02-05T17:32:42.337276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the',): 2\n",
      "('cat',): 1\n",
      "('in',): 1\n",
      "('hat',): 1\n",
      "('the',): 1\n",
      "('quick',): 1\n",
      "('brown',): 1\n",
      "('fox',): 1\n",
      "('the',): 1\n",
      "('hat',): 1\n",
      "('is',): 1\n",
      "('blue',): 1\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist, MLEProbDist\n",
    "\n",
    "for d in Docs:\n",
    "    words = word_tokenize(d.lower())\n",
    "    result = list(ngrams(words, 1))\n",
    "    # Calculate frequency distribution of bigrams\n",
    "    ngram_freq = FreqDist(result)\n",
    "    for word, frequency in ngram_freq.items():\n",
    "        print(f\"{word}: {frequency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c996bb02",
   "metadata": {
    "papermill": {
     "duration": 0.01062,
     "end_time": "2024-02-05T17:32:43.391018",
     "exception": false,
     "start_time": "2024-02-05T17:32:43.380398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601d14c5",
   "metadata": {
    "papermill": {
     "duration": 0.011569,
     "end_time": "2024-02-05T17:32:43.414827",
     "exception": false,
     "start_time": "2024-02-05T17:32:43.403258",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* **A bigram, in the context of natural language processing (NLP) and linguistics, refers to an ordered pair of consecutive words within a text or sequence of words. It is a type of n-gram, where \"n\" represents the number of words in the sequence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc92504e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:43.438593Z",
     "iopub.status.busy": "2024-02-05T17:32:43.438013Z",
     "iopub.status.idle": "2024-02-05T17:32:43.473825Z",
     "shell.execute_reply": "2024-02-05T17:32:43.472485Z"
    },
    "papermill": {
     "duration": 0.052036,
     "end_time": "2024-02-05T17:32:43.477445",
     "exception": false,
     "start_time": "2024-02-05T17:32:43.425409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the cat</th>\n",
       "      <th>cat in</th>\n",
       "      <th>in the</th>\n",
       "      <th>the hat</th>\n",
       "      <th>the quick</th>\n",
       "      <th>quick brown</th>\n",
       "      <th>brown fox</th>\n",
       "      <th>the hat</th>\n",
       "      <th>hat is</th>\n",
       "      <th>is blue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   the cat  cat in  in the  the hat  the quick  quick brown  brown fox  \\\n",
       "0        1       1       1        1          0            0          0   \n",
       "1        0       0       0        0          1            1          1   \n",
       "2        0       0       0        1          0            0          0   \n",
       "\n",
       "   the hat  hat is  is blue  \n",
       "0        1       0        0  \n",
       "1        0       0        0  \n",
       "2        1       1        1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get bi-grams of input sentence\n",
    "def bi_lst(doc):\n",
    "    wrds = doc.lower().split(' ')\n",
    "    bi_lst = []\n",
    "    for j in range(0,len(wrds)-1):\n",
    "        bi_lst.append(wrds[j:j+2])\n",
    "    return bi_lst\n",
    "\n",
    "lst = []\n",
    "for d in Docs:\n",
    "    lst.extend(bi_lst(d))\n",
    "unique_list = []\n",
    "unique_list = [item for item in lst if item not in unique_list]\n",
    "\n",
    "def count_biwrd_Doc(st,doc):\n",
    "    i=0    \n",
    "    for s in bi_lst(doc):\n",
    "        if s == st.split(' '):\n",
    "            i = i+1\n",
    "    return i\n",
    "bigram_df = pd.DataFrame(columns=list((' '.join(x) for x in unique_list))) #empty dataframe initialized with words column headers\n",
    "freq_lst=[] #empty list for each column to save word frequencies in each document\n",
    "for c in bigram_df.columns:\n",
    "    freq_lst=[]#empty the list\n",
    "    for d in Docs:\n",
    "        freq_lst.append(count_biwrd_Doc(c,d))#append the frequency of word in document d\n",
    "    bigram_df[c]=freq_lst #assign values to column\n",
    "bigram_df #display the dataframe of TF for each word in each document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c00c14a",
   "metadata": {
    "papermill": {
     "duration": 0.011232,
     "end_time": "2024-02-05T17:32:43.500756",
     "exception": false,
     "start_time": "2024-02-05T17:32:43.489524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Bigrams python function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884961e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:43.525908Z",
     "iopub.status.busy": "2024-02-05T17:32:43.524674Z",
     "iopub.status.idle": "2024-02-05T17:32:43.532659Z",
     "shell.execute_reply": "2024-02-05T17:32:43.531596Z"
    },
    "papermill": {
     "duration": 0.024248,
     "end_time": "2024-02-05T17:32:43.535939",
     "exception": false,
     "start_time": "2024-02-05T17:32:43.511691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 'cat'): 1\n",
      "('cat', 'in'): 1\n",
      "('in', 'the'): 1\n",
      "('the', 'hat'): 1\n",
      "('the', 'quick'): 1\n",
      "('quick', 'brown'): 1\n",
      "('brown', 'fox'): 1\n",
      "('the', 'hat'): 1\n",
      "('hat', 'is'): 1\n",
      "('is', 'blue'): 1\n"
     ]
    }
   ],
   "source": [
    "for d in Docs:\n",
    "    words = word_tokenize(d.lower())\n",
    "    result = list(ngrams(words, 2))\n",
    "    # Calculate frequency distribution of bigrams\n",
    "    ngram_freq = FreqDist(result)\n",
    "    for word, frequency in ngram_freq.items():\n",
    "        print(f\"{word}: {frequency}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a240736",
   "metadata": {
    "papermill": {
     "duration": 0.011605,
     "end_time": "2024-02-05T17:32:43.560275",
     "exception": false,
     "start_time": "2024-02-05T17:32:43.548670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Count Bag of Words (CBOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5540f447",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:43.586328Z",
     "iopub.status.busy": "2024-02-05T17:32:43.585832Z",
     "iopub.status.idle": "2024-02-05T17:32:43.607851Z",
     "shell.execute_reply": "2024-02-05T17:32:43.606557Z"
    },
    "papermill": {
     "duration": 0.037966,
     "end_time": "2024-02-05T17:32:43.610715",
     "exception": false,
     "start_time": "2024-02-05T17:32:43.572749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fox</th>\n",
       "      <th>the</th>\n",
       "      <th>brown</th>\n",
       "      <th>blue</th>\n",
       "      <th>hat</th>\n",
       "      <th>in</th>\n",
       "      <th>quick</th>\n",
       "      <th>is</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fox  the  brown  blue  hat  in  quick  is  cat\n",
       "0    0    2      0     0    1   1      0   0    1\n",
       "1    1    1      1     0    0   0      1   0    0\n",
       "2    0    1      0     1    1   0      0   1    0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_wrd_Doc(wrd,doc):\n",
    "    i=0\n",
    "    for w in doc.lower().split(' '):\n",
    "        if wrd == w:\n",
    "            i = i+1\n",
    "    return i\n",
    "    \n",
    "cw_df = pd.DataFrame(columns=list(wrds)) #empty dataframe initialized with words column headers\n",
    "freq_lst=[] #empty list for each column to save word frequencies in each document\n",
    "for c in tf_df.columns:\n",
    "    freq_lst=[]#empty the list\n",
    "    for d in Docs:\n",
    "        freq_lst.append(count_wrd_Doc(c,d))#append the frequency of word in document d\n",
    "    cw_df[c]=freq_lst #assign values to column\n",
    "cw_df #display the datafram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7ade389",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:43.639840Z",
     "iopub.status.busy": "2024-02-05T17:32:43.638636Z",
     "iopub.status.idle": "2024-02-05T17:32:43.650400Z",
     "shell.execute_reply": "2024-02-05T17:32:43.649455Z"
    },
    "papermill": {
     "duration": 0.028582,
     "end_time": "2024-02-05T17:32:43.653261",
     "exception": false,
     "start_time": "2024-02-05T17:32:43.624679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words representation:\n",
      "[[0 0 1 0 1 1 0 0 2]\n",
      " [0 1 0 1 0 0 0 1 1]\n",
      " [1 0 0 0 1 0 1 0 1]]\n",
      "Feature names:\n",
      "['blue' 'brown' 'cat' 'fox' 'hat' 'in' 'is' 'quick' 'the']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Create a CountVectorizer instance\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the documents to create the Bag of Words representation\n",
    "X_bow = vectorizer.fit_transform(Docs)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "# Print the Bag of Words representation\n",
    "print(\"Bag of Words representation:\")\n",
    "print(X_bow.toarray())\n",
    "print(\"Feature names:\")\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3235467",
   "metadata": {
    "papermill": {
     "duration": 0.011798,
     "end_time": "2024-02-05T17:32:43.677942",
     "exception": false,
     "start_time": "2024-02-05T17:32:43.666144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Skip-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e52c88ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:43.704749Z",
     "iopub.status.busy": "2024-02-05T17:32:43.704241Z",
     "iopub.status.idle": "2024-02-05T17:32:43.714281Z",
     "shell.execute_reply": "2024-02-05T17:32:43.712908Z"
    },
    "papermill": {
     "duration": 0.026881,
     "end_time": "2024-02-05T17:32:43.717131",
     "exception": false,
     "start_time": "2024-02-05T17:32:43.690250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'the': 3, 'cat': 1, 'in': 2, 'hat': 4},\n",
       " {'the': 0, 'quick': 1, 'brown': 2, 'fox': 3},\n",
       " {'the': 0, 'hat': 1, 'is': 2, 'blue': 3}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Create a vocabulary (unique words with indices)\n",
    "vocab = []\n",
    "for d in Docs:\n",
    "    vocab.append({word: idx for idx, word in enumerate(d.lower().split())})\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1905fbcb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:43.747347Z",
     "iopub.status.busy": "2024-02-05T17:32:43.746615Z",
     "iopub.status.idle": "2024-02-05T17:32:43.756546Z",
     "shell.execute_reply": "2024-02-05T17:32:43.754592Z"
    },
    "papermill": {
     "duration": 0.029662,
     "end_time": "2024-02-05T17:32:43.760004",
     "exception": false,
     "start_time": "2024-02-05T17:32:43.730342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate training pairs (target word, context word)\n",
    "window_size = 2\n",
    "training_pairs = []\n",
    "context_words = []\n",
    "for d in Docs:\n",
    "    t=[]\n",
    "    c=[]\n",
    "    for i, target_word in enumerate(d.lower().split(' ')):\n",
    "        start = max(0, i - window_size)\n",
    "        end = min(len(d.lower().split(' ')), i + window_size + 1)\n",
    "        c = [d.lower().split(' ')[j] for j in range(start, end) if j != i]\n",
    "        for context_word in c:\n",
    "            t.append((target_word, context_word))\n",
    "    training_pairs.append(t)\n",
    "    context_words.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f38a72ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:43.790193Z",
     "iopub.status.busy": "2024-02-05T17:32:43.789690Z",
     "iopub.status.idle": "2024-02-05T17:32:43.799774Z",
     "shell.execute_reply": "2024-02-05T17:32:43.798117Z"
    },
    "papermill": {
     "duration": 0.029617,
     "end_time": "2024-02-05T17:32:43.802329",
     "exception": false,
     "start_time": "2024-02-05T17:32:43.772712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('the', 'cat'),\n",
       "  ('the', 'in'),\n",
       "  ('cat', 'the'),\n",
       "  ('cat', 'in'),\n",
       "  ('cat', 'the'),\n",
       "  ('in', 'the'),\n",
       "  ('in', 'cat'),\n",
       "  ('in', 'the'),\n",
       "  ('in', 'hat'),\n",
       "  ('the', 'cat'),\n",
       "  ('the', 'in'),\n",
       "  ('the', 'hat'),\n",
       "  ('hat', 'in'),\n",
       "  ('hat', 'the')],\n",
       " [('the', 'quick'),\n",
       "  ('the', 'brown'),\n",
       "  ('quick', 'the'),\n",
       "  ('quick', 'brown'),\n",
       "  ('quick', 'fox'),\n",
       "  ('brown', 'the'),\n",
       "  ('brown', 'quick'),\n",
       "  ('brown', 'fox'),\n",
       "  ('fox', 'quick'),\n",
       "  ('fox', 'brown')],\n",
       " [('the', 'hat'),\n",
       "  ('the', 'is'),\n",
       "  ('hat', 'the'),\n",
       "  ('hat', 'is'),\n",
       "  ('hat', 'blue'),\n",
       "  ('is', 'the'),\n",
       "  ('is', 'hat'),\n",
       "  ('is', 'blue'),\n",
       "  ('blue', 'hat'),\n",
       "  ('blue', 'is')]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f90fc040",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:43.831265Z",
     "iopub.status.busy": "2024-02-05T17:32:43.830796Z",
     "iopub.status.idle": "2024-02-05T17:32:43.839512Z",
     "shell.execute_reply": "2024-02-05T17:32:43.837834Z"
    },
    "papermill": {
     "duration": 0.028357,
     "end_time": "2024-02-05T17:32:43.843627",
     "exception": false,
     "start_time": "2024-02-05T17:32:43.815270",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['in', 'the'], ['quick', 'brown'], ['hat', 'is']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c4df3ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:43.874382Z",
     "iopub.status.busy": "2024-02-05T17:32:43.873889Z",
     "iopub.status.idle": "2024-02-05T17:32:43.886815Z",
     "shell.execute_reply": "2024-02-05T17:32:43.885103Z"
    },
    "papermill": {
     "duration": 0.033373,
     "end_time": "2024-02-05T17:32:43.889713",
     "exception": false,
     "start_time": "2024-02-05T17:32:43.856340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'the': array([0.84529526, 0.69903951, 0.28539354, 0.11736014, 0.65626588,\n",
       "         0.08263976, 0.99767143, 0.28758688, 0.26407711, 0.13148117]),\n",
       "  'cat': array([0.48804358, 0.59325503, 0.71037303, 0.40248577, 0.63705859,\n",
       "         0.03943421, 0.89622593, 0.74615319, 0.63991473, 0.04905593]),\n",
       "  'in': array([0.30902045, 0.68482678, 0.16373436, 0.84309403, 0.36842233,\n",
       "         0.3958363 , 0.13988066, 0.20406499, 0.45517246, 0.17487886]),\n",
       "  'hat': array([0.80510322, 0.86534605, 0.53292194, 0.9258283 , 0.38611018,\n",
       "         0.70490979, 0.58199763, 0.57832354, 0.01628012, 0.85001542])},\n",
       " {'the': array([0.50691032, 0.29632617, 0.11346918, 0.4250841 , 0.46255449,\n",
       "         0.56645798, 0.60185999, 0.63028282, 0.62756915, 0.14307344]),\n",
       "  'quick': array([0.81222574, 0.46387643, 0.82730484, 0.68975084, 0.75186311,\n",
       "         0.49662962, 0.93318671, 0.74401174, 0.81626842, 0.91329522]),\n",
       "  'brown': array([0.77325203, 0.29572043, 0.40950794, 0.40860489, 0.66149743,\n",
       "         0.5108963 , 0.84747143, 0.33569202, 0.02016506, 0.47381295]),\n",
       "  'fox': array([0.86148862, 0.39008349, 0.89941274, 0.90047385, 0.90668329,\n",
       "         0.21723016, 0.71390923, 0.77120442, 0.57270365, 0.1085874 ])},\n",
       " {'the': array([0.36296178, 0.56740031, 0.61700787, 0.05232509, 0.77451317,\n",
       "         0.76392254, 0.33009131, 0.39986296, 0.9508244 , 0.60968802]),\n",
       "  'hat': array([0.5878053 , 0.13840351, 0.83216516, 0.93763536, 0.81204713,\n",
       "         0.22333305, 0.95822598, 0.87333068, 0.81902385, 0.79728697]),\n",
       "  'is': array([1.78393386e-01, 6.09633521e-01, 6.00198017e-01, 3.76722739e-01,\n",
       "         3.73891610e-04, 8.67778952e-01, 1.13723416e-01, 8.64355917e-01,\n",
       "         5.25238900e-01, 1.24967219e-01]),\n",
       "  'blue': array([0.05568123, 0.85155144, 0.50437277, 0.19499142, 0.98760367,\n",
       "         0.50206039, 0.87703248, 0.06045567, 0.78318074, 0.39850403])}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize word vectors randomly\n",
    "embedding_dim = 10\n",
    "learning_rate = 0.01\n",
    "epochs = 10000\n",
    "word_vectors = []\n",
    "for v in vocab:\n",
    "    word_vectors.append({word: np.random.rand(embedding_dim) for word in v})#initialize random values vector for each word \n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1760720",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:43.918931Z",
     "iopub.status.busy": "2024-02-05T17:32:43.918245Z",
     "iopub.status.idle": "2024-02-05T17:32:49.688019Z",
     "shell.execute_reply": "2024-02-05T17:32:49.686248Z"
    },
    "papermill": {
     "duration": 5.788235,
     "end_time": "2024-02-05T17:32:49.690872",
     "exception": false,
     "start_time": "2024-02-05T17:32:43.902637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: -2.455161845659121\n",
      "Epoch 1000, Loss: 2.895171525320865e-06\n",
      "Epoch 2000, Loss: 1.2455481091044738e-11\n",
      "Epoch 3000, Loss: -0.0\n",
      "Epoch 4000, Loss: -0.0\n",
      "Epoch 5000, Loss: -0.0\n",
      "Epoch 6000, Loss: -0.0\n",
      "Epoch 7000, Loss: -0.0\n",
      "Epoch 8000, Loss: -0.0\n",
      "Epoch 9000, Loss: -0.0\n",
      "-------------------------------\n",
      "Epoch 0, Loss: -2.911662972370301\n",
      "Epoch 1000, Loss: 7.762651243338787e-05\n",
      "Epoch 2000, Loss: 3.656747671577919e-08\n",
      "Epoch 3000, Loss: 1.726285781004556e-11\n",
      "Epoch 4000, Loss: 8.104628079763676e-15\n",
      "Epoch 5000, Loss: -0.0\n",
      "Epoch 6000, Loss: -0.0\n",
      "Epoch 7000, Loss: -0.0\n",
      "Epoch 8000, Loss: -0.0\n",
      "Epoch 9000, Loss: -0.0\n",
      "-------------------------------\n",
      "Epoch 0, Loss: -1.7799870869561538\n",
      "Epoch 1000, Loss: 0.00016867172622069302\n",
      "Epoch 2000, Loss: 7.955753705880423e-08\n",
      "Epoch 3000, Loss: 3.755784572305218e-11\n",
      "Epoch 4000, Loss: 1.7763568394002662e-14\n",
      "Epoch 5000, Loss: -0.0\n",
      "Epoch 6000, Loss: -0.0\n",
      "Epoch 7000, Loss: -0.0\n",
      "Epoch 8000, Loss: -0.0\n",
      "Epoch 9000, Loss: -0.0\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(training_pairs)):\n",
    "    # Train the Skip-gram model\n",
    "    for epoch in range(epochs):\n",
    "    \n",
    "        for target_word, context_word in training_pairs[i]:\n",
    "            # Forward pass\n",
    "            input_vector = word_vectors[i][target_word]\n",
    "            output_vector = word_vectors[i][context_word]\n",
    "\n",
    "            # Calculate loss (using negative log likelihood)\n",
    "            error = -np.log(np.exp(np.dot(input_vector, output_vector)))\n",
    "\n",
    "            # Backward pass (update word vectors using gradient descent)\n",
    "            gradient = input_vector * np.exp(np.dot(input_vector, output_vector)) / (1 + np.exp(np.dot(input_vector, output_vector)))\n",
    "            word_vectors[i][target_word] -= learning_rate * gradient\n",
    "            word_vectors[i][context_word] -= learning_rate * gradient\n",
    "\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {error}\")\n",
    "    print('-------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e218f608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-05T17:32:49.721036Z",
     "iopub.status.busy": "2024-02-05T17:32:49.720545Z",
     "iopub.status.idle": "2024-02-05T17:32:49.731679Z",
     "shell.execute_reply": "2024-02-05T17:32:49.729391Z"
    },
    "papermill": {
     "duration": 0.029771,
     "end_time": "2024-02-05T17:32:49.734347",
     "exception": false,
     "start_time": "2024-02-05T17:32:49.704576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'the': [-2.44113355e-28 -2.87758094e-28 -3.37613298e-28 -3.64563012e-28\n",
      " -1.54601888e-28 -2.29515671e-28 -2.59581436e-28 -3.61020069e-28\n",
      " -8.32105908e-29 -3.04462084e-28]\n",
      "Vector for 'cat': [3.43064380e-28 4.04400457e-28 4.74464401e-28 5.12338147e-28\n",
      " 2.17269558e-28 3.22549544e-28 3.64802428e-28 5.07359076e-28\n",
      " 1.16939894e-28 4.27875387e-28]\n",
      "Vector for 'in': [-1.17035864e-28 -1.37960569e-28 -1.61862772e-28 -1.74783339e-28\n",
      " -7.41211623e-29 -1.10037261e-28 -1.24451765e-28 -1.73084737e-28\n",
      " -3.98938577e-29 -1.45969004e-28]\n",
      "Vector for 'hat': [4.63675245e-28 5.46575197e-28 6.41271465e-28 6.92460452e-28\n",
      " 2.93654840e-28 4.35948025e-28 4.93055720e-28 6.85730894e-28\n",
      " 1.58052357e-28 5.78303188e-28]\n",
      "-------------------------------\n",
      "Vector for 'the': [ 3.11506050e-18  1.72387911e-18  1.91063019e-18  5.17514425e-18\n",
      "  3.97560809e-18  1.31159958e-18  1.71048919e-18  5.87997419e-18\n",
      "  5.42181347e-18 -4.98986794e-18]\n",
      "Vector for 'quick': [-1.91077471e-18 -1.05742557e-18 -1.17197847e-18 -3.17442784e-18\n",
      " -2.43863367e-18 -8.04533750e-19 -1.04921220e-18 -3.60676975e-18\n",
      " -3.32573447e-18  3.06077955e-18]\n",
      "Vector for 'brown': [-1.90122083e-18 -1.05213844e-18 -1.16611858e-18 -3.15855570e-18\n",
      " -2.42644050e-18 -8.00511081e-19 -1.04396614e-18 -3.58873590e-18\n",
      " -3.30910579e-18  3.04547565e-18]\n",
      "Vector for 'fox': [ 3.05322499e-18  1.68965925e-18  1.87270323e-18  5.07241506e-18\n",
      "  3.89669029e-18  1.28556367e-18  1.67653512e-18  5.76325377e-18\n",
      "  5.31418777e-18 -4.89081656e-18]\n",
      "-------------------------------\n",
      "Vector for 'the': [-5.88448391e-19  7.95760544e-18  1.81652994e-18 -4.83420431e-18\n",
      "  1.02699486e-17  4.89850852e-18  4.35319749e-18 -5.22008482e-18\n",
      "  7.32930250e-18  3.45038786e-18]\n",
      "Vector for 'hat': [ 3.60953601e-19 -4.88118649e-18 -1.11425748e-18  2.96529565e-18\n",
      " -6.29957526e-18 -3.00473978e-18 -2.67024659e-18  3.20199433e-18\n",
      " -4.49578616e-18 -2.11646415e-18]\n",
      "Vector for 'is': [ 3.59148833e-19 -4.85678056e-18 -1.10868619e-18  2.95046917e-18\n",
      " -6.26807738e-18 -2.98971608e-18 -2.65689536e-18  3.18598436e-18\n",
      " -4.47330723e-18 -2.10588183e-18]\n",
      "Vector for 'blue': [-5.76767396e-19  7.79964300e-18  1.78047091e-18 -4.73824294e-18\n",
      "  1.00660850e-17  4.80127068e-18  4.26678435e-18 -5.11646353e-18\n",
      "  7.18381219e-18  3.38189594e-18]\n",
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "#word vectors\n",
    "for i in range(0,len(training_pairs)):\n",
    "    for word, vector in word_vectors[i].items():\n",
    "        print(f\"Vector for '{word}': {vector}\")\n",
    "    print('-------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.503552,
   "end_time": "2024-02-05T17:32:50.776085",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-05T17:32:34.272533",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
